# 神经网络卷积层概况     
## 卷积层图

![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/general.png)  
图中有两个卷积层，同时我们把卷积核称之为filter

第一个convolution layer 由input image 变成 3 feature maps ，需要3个filter  
第二个convolution layer 由 3个feature maps 变成 5个feature maps ,需要5个filter  
总结： 需要几个feature maps 就需要几个 filer. 原因如下图：  
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/matrice1.gif)  
由上图看到，我们需要2个feature maps输出，就需要2个filter W0 和 W1


## 矩阵卷积怎么算   
**原则** 把卷积核贴着输入矩阵，一位一位对着乘起来，然后所有值相加，接着再把卷积核位移，重复同样的运算  
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/1.png)  
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/2.png)
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/3.gif)  
上面是卷积核位移步长为 1 的， 下面是步长为 2    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/4.png)    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/5.png)    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/6.png)    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/7.png)    

**卷积后矩阵大小的计算**      
**公式**     
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/8.PNG)    

公式里，W1 是 卷积前矩阵的宽， F 是卷积核filter的宽 ， P 是指外圈补了几层 0 ， S 是卷积核移动的步长 ， W2就是卷积后矩阵的宽  
H 也是一样的道理
在上面的例子中，W1 = 5      F = 3     P= 0     S = 2    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/9.PNG)    

计算卷积后矩阵大小的函数 calculate_output_size 如下    
```
def calculate_output_size(input_size,filter_size,zero_padding,stride):
    return (input_size - filter_size + 2*zero_padding)/stride +1
```
计算二维卷积的函数 conv_2d 如下
```
def conv_2d(input_array,kernel_array):
    
    input_array_size=input_array.shape[0]
    kernel_array_size=kernel_array.shape[0]
    
    output_array_size=calculate_output_size(input_array_size,kernel_array_size,0,1)
    for i in range(output_array_size):
        for j in range(output_array_size):
            output_array[i][j]=np.sum(input_array[i+kernel_array_size:j+kernel_array_size]*kernel)
    return output_array
    
```
## 卷积层的正向传递    
![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/matrice1.gif)   


**关键**    
input 是7x7x3 矩阵，深度为3 那么filter 的深度也要求一定是3 ， output 的深度取决于 filter 的个数，图中有2个filter ,所以output的深度是2

### 初始化类          
我们需要两个类：**ConvoLayer** 和 **Filter**

**ConvoLayer** 
用来存储 input ， 卷积层，output 的基本信息，主要涉及维度和初始化
```
class ConvoLayer(object):

    def _init_(self, input_width,input_height,input_depth,filter_height,filter_width,filter_number,zero_padding,stride,learning_rate,activators):

        '''
        ConvoLayer has 3 parts:
            1. input array  ----- height width depth
            2. filter       ----- height width depth(the same as input array),number
            3. output array ----- height width depth (the same as filter number)


        we also need to combine the N filter together to forme a total filter
            
        '''

        # parameters input array
        self.input_height = input_height
        self.input_width = input_width
        self.input_depth = input_depth

        # parameters filter
        self.filter_height = filter_height
        self.filter_width = filter_width
        self.filter_depth =  input_depth
        self.filter_number = filter_number


        # parameters output
        self.output_height = calculate_output_size(input_height, filter_height,zero_padding,stride)
        self.output_width = calculate_output_size(input_width, filter_width,zero_padding,stride)
        self.output_depth = filter_number

        #other parameters
        self.zero_padding = zero_padding
        self.stride = stride
        self.activators = activators
        self.learning_rate = learning_rate

        # make up of filter
        self.filter_total = []
        for i in range(filter_number):
            filter_total.append(Filter(filter_height,filter_width,filter_depth))
```

**Filter**
主要用于保存权重w ，偏置b 和梯度变化和更新
权重、偏置更新：
在SGD里，由于有mini-batch的存在，权重和偏置的更新关系如下,这里m是mini_batch 的大小


![](https://github.com/WuFan1992/CNN-Convolutional-Neural-Network/blob/master/convolution%20layer/image-convolution%20layer/10.PNG)
